[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/getstart/getstart2.html",
    "href": "posts/getstart/getstart2.html",
    "title": "Getting started with Acoular - Part 2",
    "section": "",
    "text": "This is the second in a series of three blog posts about the basic use of Acoular. It assumes that you already have read the first post and continues by explaining some more concepts and additional methods.\nAcoular is a Python library that processes multichannel data (up to a few hundred channels) from acoustic measurements with a microphone array. The focus of the processing is on the construction of a map of acoustic sources. This is somewhat similar to taking an acoustic photograph of some sound sources. \nTo continue, we do the same set up as in Part 1. We define TimeSamples, PowerSpectra, MicGeom, RectGrid and SteeringVector objects and set up a BeamformerBase.\n\nimport acoular\nts = acoular.TimeSamples( name=\"three_sources.h5\" )\nps = acoular.PowerSpectra( time_data=ts, block_size=128, window=\"Hanning\" )\nmg = acoular.MicGeom( from_file=\"array_64.xml\" )\nrg = acoular.RectGrid( x_min=-0.2, x_max=0.2,\n                       y_min=-0.2, y_max=0.2,\n                       z=0.3, increment=0.01 )\nst = acoular.SteeringVector( grid=rg, mics=mg )\nbb = acoular.BeamformerBase( freq_data=ps, steer=st )\n\nWe can now plot the result the same way as we already did in Part 1.\n\n%matplotlib notebook\nimport matplotlib.pyplot as plt\nLm = acoular.L_p( bb.synthetic(8000,3) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n[('three_sources_cache.h5', 1)]\n\n\n\n\n\n\n\n\nThe result is obviously the same as before.\nIt was computed using a variant of the beamformer that applies the diagonal removal technique. This setting is the default and it means that we ignore the information in the main diagonal of the CSM, where the auto spectra (self-cross spectra) are stored. This is not too harmful in most cases and has the advantage that the map contains less artifacts. After this explanation, we of course now want to see the result with the full CSM including the diagonal (and hopefully with those artifacts).\nWe achieve this by setting the corresponding flag of the bb object. Have a look at the documentation on BeamformerBase to understand the r_diag flag.\n\nbb.r_diag = False\n\nObviously nothing happens (right away). This is due to the lazy evaluation again. To get the result we again have to explicitly ask for it and then we can again plot it.\n\nLm = acoular.L_p( bb.synthetic(8000,3) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n\n\n\n\n\n\nNice! But indeed there are some artifacts that we may have mistaken for additional weak sound sources if we did not know that there are exactly three sound sources.\nChanges in other objects will also affect the beamformer. To try this out, we change the file name in the ts object. Now this object gets data from new time histories. The ps and bb objects “know” about this automatically. No need to inform these other objects about the change. We can immediately ask for the new result and it will be computed.\n\nts.name=\"two_sources.h5\"\nLm = acoular.L_p( bb.synthetic( 8000, 3 ) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n[('two_sources_cache.h5', 1)]\n\n\n\n\n\n\n\n\nThere are only two sources. The result is different, obviously!\nNow let us try a different type of beamformer. Instead of standard beamforming, we use functional beamforming. We set up a new object bf and specify the \\(\\gamma\\) parameter which is specific to that type of beamformer. We also use the same time histories for the three sources scene as before.\n\nts.name=\"three_sources.h5\"\nbf = acoular.BeamformerFunctional( freq_data=ps, steer=st, gamma=50  )\nLm = acoular.L_p( bf.synthetic(8000,3) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n[('two_sources_cache.h5', 1), ('three_sources_cache.h5', 1)]\n\n\n\n\n\n\n\n\nNote the much smaller lobes of this beamformer. In other words, the image is less blurry.\nInstead of just beamforming we can apply a deconvolution method. Deconvolution methods aim to remove all blur and artifacts from the result. The original blurry beamforming result can be understood as the convolution of the ideal image with a filter kernel (the point spread function) which is specific to the beamforming algorithm. Deconvolution is any technique that attempts to reverse this convolution.\nIn Acoular the deconvolution is achieved in a similar way to beamforming. Instead of defining a BeamformerBase type of object, we have to use a “beamformer” with deconvolution. In our example we use the CleanSC deconvolution method and BeamformerCleansc type of object. Despite the python class name we chose it is not just a beamformer.\n\nts.name=\"three_sources.h5\"\nbs = acoular.BeamformerCleansc( freq_data=ps, steer=st )\nLm = acoular.L_p( bs.synthetic( 8000, 3) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n[('two_sources_cache.h5', 1), ('three_sources_cache.h5', 2)]\n\n\n\n\n\n\n\n\nDepending on the computer, this computation may take some seconds already. Now there is just one grid “point” per source and the image looks perfect.\nYou may have noticed that whenever a results is computed, some messages about cache files appear. This happens because all computed results are cached to a file on disk. If one ask for the same result twice, it is still computed only once to save computing time and effort. This even means at the next start of this notebook no recalculation is necessary and all results are immediately available!\nWe can try out the automatic caching mechanism by setting up another BeamformerCleansc object bs1 with all the same parameters as the bs object we did already use.\n\nbs1 = acoular.BeamformerCleansc( freq_data=ps, steer=st )\nprint( bs, bs1 )\n\n&lt;acoular.fbeamform.BeamformerCleansc object at 0x7f945f042290&gt; &lt;acoular.fbeamform.BeamformerCleansc object at 0x7f945efdbcb0&gt;\n\n\nNote that while we have two identical objects, they are not the same object. Thus, the bs1 does not know about the results while bs still does. If we now trigger the computation of the results for bs1 they are not actually computed, but just read from the cache. No noteable delay will happen when executing the following commands.\n\nLm = acoular.L_p( bs1.synthetic(8000,3) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend() )\nplt.colorbar();\n\n[('two_sources_cache.h5', 1), ('three_sources_cache.h5', 3)]\n\n\n\n\n\n\n\n\nThis is indeed the same result as before.\nHowever, the cache is not used when parameters are changing. This is desirable because the result may also change. We demonstrate this here by changing one parameter of the bs object.\n\nprint( bs.damp )\nbs.damp = 0.99\n\n0.6\n\n\nWith the new value, a new computation is necessary.\n\nLm = acoular.L_p( bs.synthetic( 8000, 3 ) )\nplt.figure()\nplt.imshow( Lm.T, origin=\"lower\", vmin=Lm.max()-15, extent=rg.extend())\nplt.colorbar();\n\n\n\n\n\n\n\nThis took again some time. In our simple example the result looks not much different, but there was no way to know this before.\nIn this blog post, we learned how to use alternative methods like functional beamforming and CleanSC. There are many more such methods implemented in Acoular and now you know how to check them out. The last part of this blog post series is about time domain beamforming."
  }
]